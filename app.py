"""
app.py
Dissertation dashboard â€” Pinus taeda Yield Prediction
-----------------------------------------------------
Navigation  : sidebar radio buttons (Home + 3 project pages)
Layout      : scrollytelling â€” markdown narrative â†’ chart â†’ narrative â†’ chart
Text        : loaded from markdown/ folder (external .md files)
Charts      : generated by modules/proj*_plots.py (Plotly figures)
Data        : cached via modules/data_loader.py (@st.cache_data)
"""

import streamlit as st
from pathlib import Path

from modules.data_loader import load_all_data
from modules import proj1_plots, proj2_plots, proj3_plots


# ---------------------------------------------------------------------------
# Cached plot builders â€” prevent re-generating heavy figures on every render
# ---------------------------------------------------------------------------
@st.cache_data(show_spinner=False)
def _build_p2_animated(df):
    return proj2_plots.plot_p2_scatter_animated(df)


@st.cache_data(show_spinner=False)
def _build_p2_temporal(df):
    return proj2_plots.plot_p2_temporal_importance(df)


@st.cache_data(show_spinner=False)
def _build_p2_tph(df):
    return proj2_plots.plot_p2_scatter_tph(df)


@st.cache_data(show_spinner=False)
def _build_p2_growth(df):
    return proj2_plots.plot_p2_growth_curve(df)


@st.cache_data(show_spinner=False)
def _build_p3_rmse_tph(df):
    return proj3_plots.plot_p3_rmse_by_tph(df)



# ---------------------------------------------------------------------------
# Page config â€” must be the first Streamlit call
# ---------------------------------------------------------------------------
st.set_page_config(
    page_title="Pinus taeda Â· Yield Prediction Dashboard",
    page_icon="ðŸŒ²",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ---------------------------------------------------------------------------
# Design tokens
# ---------------------------------------------------------------------------
_PALETTE = {
    "sage":  "#7A9E7E",
    "teal":  "#5B7B7A",
    "beige": "#C5B89A",
    "dark":  "#3D5A5A",
    "light": "#F5F0E8",
    "text":  "#2C3E35",
    "bg":    "#FAFAF7",
}

_PAGES = [
    "Home",
    "Project 1: Individual Trees",
    "Project 2: Stand Dynamics",
    "Project 3: Remote Sensing",
]


# ---------------------------------------------------------------------------
# CSS injection
# ---------------------------------------------------------------------------
def _inject_css() -> None:
    st.markdown(f"""
    <style>
      /* ---- Global background ---- */
      .stApp {{ background-color: {_PALETTE['bg']}; }}

      /* ---- Sidebar ---- */
      [data-testid="stSidebar"] {{
          background-color: {_PALETTE['dark']};
      }}
      [data-testid="stSidebar"] * {{
          color: {_PALETTE['light']} !important;
      }}
      [data-testid="stSidebar"] .stRadio label span {{
          color: {_PALETTE['beige']} !important;
          font-size: 0.9rem;
      }}
      [data-testid="stSidebar"] hr {{
          border-color: {_PALETTE['teal']} !important;
          opacity: 0.45;
      }}

      /* ---- Headings ---- */
      h1, h2, h3, h4, h5, h6,
      [data-testid="stMarkdownContainer"] h1,
      [data-testid="stMarkdownContainer"] h2,
      [data-testid="stMarkdownContainer"] h3,
      [data-testid="stMarkdownContainer"] h4,
      [data-testid="stMarkdownContainer"] h5,
      [data-testid="stMarkdownContainer"] h6 {{
          color: {_PALETTE['dark']} !important;
          font-family: Georgia, serif !important;
      }}

      /* ---- Horizontal rule ---- */
      hr {{ border-color: {_PALETTE['sage']}; opacity: 0.35; }}

      /* ---- Metric cards ---- */
      [data-testid="metric-container"] {{
          background-color: {_PALETTE['light']};
          border: 1px solid {_PALETTE['sage']};
          border-radius: 10px;
          padding: 14px 18px;
      }}

      /* ---- Scrollytelling section label ---- */
      .section-label {{
          border-left: 4px solid {_PALETTE['sage']};
          padding: 6px 0 6px 14px;
          margin: 28px 0 12px 0;
      }}
      .section-label span.eyebrow {{
          display: block;
          font-size: 0.72rem;
          text-transform: uppercase;
          letter-spacing: 2.5px;
          color: {_PALETTE['sage']};
          font-weight: 700;
          font-family: sans-serif;
      }}
      .section-label span.heading {{
          display: block;
          font-size: 1.1rem;
          color: {_PALETTE['dark']};
          font-family: Georgia, serif;
          margin-top: 2px;
      }}

      /* ---- Selectbox label ---- */
      label[data-testid="stWidgetLabel"] {{
          color: {_PALETTE['teal']};
          font-size: 0.85rem;
          font-family: Georgia, serif;
      }}

      /* ---- Plotly chart container subtle card ---- */
      [data-testid="stPlotlyChart"] {{
          border-radius: 10px;
          background: #FFFFFF;
          padding: 6px;
          box-shadow: 0 1px 6px rgba(60,90,80,0.07);
      }}

      /* ---- Main content text ---- */
      .stMarkdown p,
      .stMarkdown li,
      .stMarkdown ol,
      .stMarkdown ul,
      [data-testid="stMarkdownContainer"] p,
      [data-testid="stMarkdownContainer"] li {{
          color: #1A1A1A !important;
      }}

      /* ---- Expander content text ---- */
      [data-testid="stExpander"] summary span,
      [data-testid="stExpander"] p,
      [data-testid="stExpander"] td,
      [data-testid="stExpander"] th,
      [data-testid="stExpander"] li {{
          color: #1A1A1A !important;
      }}
    </style>
    """, unsafe_allow_html=True)


# ---------------------------------------------------------------------------
# Utility helpers
# ---------------------------------------------------------------------------
def _load_md(filename: str) -> str:
    """Read a markdown file from the markdown/ directory."""
    path = Path("markdown") / filename
    if path.exists():
        return path.read_text(encoding="utf-8")
    return (
        f"> **Content file `{filename}` not found.**  \n"
        f"> Place it in the `markdown/` directory to populate this section."
    )


def _section(eyebrow: str, heading: str = "") -> None:
    """Render a styled scrollytelling section divider."""
    heading_html = f'<span class="heading">{heading}</span>' if heading else ""
    st.markdown(f"""
    <div class="section-label">
      <span class="eyebrow">{eyebrow}</span>
      {heading_html}
    </div>
    """, unsafe_allow_html=True)


# ---------------------------------------------------------------------------
# Page renderers
# ---------------------------------------------------------------------------
def _page_home() -> None:
    st.markdown(_load_md("landing.md"), unsafe_allow_html=True)


def _page_project1(data: dict) -> None:
    # ---- Narrative intro -------------------------------------------------
    st.markdown(_load_md("project1.md"), unsafe_allow_html=True)

    # ---- Scatter: Observed vs Predicted ----------------------------------
    _section("The Results", "Observed vs. Predicted Individual Tree Volume")
    st.caption(
        "Each point is one tree. Hover for full metadata."
    )
    fig_scatter = proj1_plots.plot_p1_scatter(data["proj1"])
    st.plotly_chart(fig_scatter, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

At the individual-tree level, **Support Vector Regression (SVR)** demonstrates superior predictive performance over the Random Forest (RF) model. As visualized above, the SVR predictions ($R^2 = 0.59$) maintain a tighter, more consistent clustering along the 1:1 line of perfect agreement compared to the wider dispersion seen in the RF model ($R^2 = 0.47$).

While both algorithms successfully capture the general growth trajectories using only drone-derived metrics, they exhibit a slight tendency to underpredict the volume of the very largest trees. This trailing off at the higher volumes highlights a known limitation in high-density stands, where overlapping crowns can obscure the true structural dimensions from the LiDAR sensor.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- Volume by TPH subplots ------------------------------------------
    _section("Stand Density Breakdown", "Volume Predictions by Trees per Hectare (TPH)")
    st.caption(
        "Each subplot shows one stand density treatment. "
        "Use the tabs to switch between model predictions."
    )
    fig_tph = proj1_plots.plot_p1_scatter_tph(data["proj1"])
    st.plotly_chart(fig_tph, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

Stratifying the predictions by planting density reveals a stark **inverse relationship between stand density and model accuracy**. Both algorithms perform optimally in lower-density environments (618 TPH) and the variable-density Nelder trials, with SVR consistently maintaining a higher $R^2$ than Random Forest.

However, as stand density increases to the maximum of 1,853 TPH, predictive performance degrades substantially across the board (with RF dropping to an $R^2$ of 0.08 and SVR to 0.31). This visualizes a critical operational constraint: in highly dense stands, severe canopy interlocking limits the ability of LiDAR algorithms to accurately delineate individual tree crowns. This physical overlapping introduces unavoidable segmentation noise into the predictor variables, effectively capping the accuracy of individual-tree yield forecasts in highly crowded conditions.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- Feature Importance ----------------------------------------------
    _section("The Why", "Feature Importance by Model")
    st.caption(
        "Use the tabs at the top-left of the chart to switch between model importance profiles."
    )
    fig_imp = proj1_plots.plot_p1_importance(data["proj1_importance"])
    st.plotly_chart(fig_imp, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

The feature importance analysis reveals that while both algorithms successfully predict yield, they "learn" the forest structure using different biological drivers:

*   **Random Forest (RF)** relies heavily on vertical stratification. Its predictions are dominated by absolute tree top height (`Z`) and height-based competition (`CI_Z`), indicating that light competition and vertical dominance are the primary drivers of yield in this model.
*   **Support Vector Regression (SVR)** prioritizes crown architecture and photosynthetic capacity. It relies heavily on upper crown surface areas (`sfa2`, `sfa4`), height to live crown (`HTLC.x`), and leaf area index competition (`CI_LAI`).

Crucially, both models heavily prioritize distance-dependent **Competition Indices (CIs)** alongside Individual Tree Crown (ITC) metrics. This confirms a fundamental ecological reality: accurately forecasting future yield requires measuring not just the current size of a tree, but the spatial, competitive stress exerted by its immediate neighbors. Furthermore, isolating just these top features allows for highly accurate "Reduced" models, greatly streamlining data processing for operational forestry.

</div>
""", unsafe_allow_html=True)

    with st.expander("Variable Glossary"):
        st.markdown("""
| Variable | Full Description |
|---|---|
| **sfa1** | Surface area of 3D convex hull for lidar returns in top 10% of the height |
| **sfa2** | Surface area of 3D convex hull for lidar returns in top 20% of the height |
| **sfa3** | Surface area of 3D convex hull for lidar returns in top 30% of the height |
| **sfa4** | Surface area of 3D convex hull for lidar returns in top 40% of the height |
| **sfa5** | Surface area of 3D convex hull for lidar returns in top 50% of the height |
| **HTLC.x** | Estimated height to the live crown |
| **CI_LAI** | Competition index using leaf area index |
| **UndPrp** | Proportion of returns in the understory compared to in the canopy (0â€“1) |
| **Z** | Tree top height |
| **CI_Z** | Competition index using tree top height |
| **CI_under** | Competition index using understory presence |
| **CI_Carea** | Competition index using areas derived from convex hull estimate of crown area |
| **SILVA2** | Competition index based on number of competing crowns |
| **CI_sfa5** | Competition index using the surface area of the 3D convex hull for lidar returns in the top 50% of the height |
""")


def _page_project2(data: dict) -> None:
    # ---- Narrative intro -------------------------------------------------
    st.markdown(_load_md("project2.md"), unsafe_allow_html=True)

    # ---- Animated scatter ------------------------------------------------
    _section("The Results", "Volume Predictions Across Stand Age")
    st.caption(
        "Drag the **age slider** or press **Play** to animate through stand ages. "
        "Watch the scatter cloud tighten as predictions converge with maturity."
    )
    fig_anim = _build_p2_animated(data["proj2"])
    st.plotly_chart(fig_anim, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

Tracking predictive accuracy across the seven-year horizon reveals a striking difference in algorithmic stability and **temporal transferability**.

*   **Random Forest (RF)** demonstrates exceptional longitudinal robustness. It successfully captures the growth trajectory immediately, maintaining a high and stable accuracy ($R^2$ ranging from 0.83 to 0.88) from the first year of prediction all the way to year seven.
*   **Support Vector Regression (SVR)**, in contrast, shows a distinct "learning curve" over time. It struggles with noise in the early forecasting years ($R^2 = 0.55$ at Age 9) but steadily improves and converges toward higher accuracy as the stand matures and canopy closure intensifies ($R^2 = 0.74$ by Age 14).

Ultimately, the tight, consistent clustering of the RF predictions along the 1:1 line proves that a **single early-age LiDAR acquisition (Age 8)** captures a sufficiently deep snapshot of the competitive hierarchy to accurately forecast individual tree yield for nearly a decade into the future.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- Growth curves ---------------------------------------------------
    _section("Growth Trajectories", "Volume Growth Curves Over Stand Age")
    st.caption(
        "Mean observed (dashed) and mean predicted (solid) volume per tree across stand ages. "
        "Shaded bands show the 25thâ€“75th percentile spread. "
        "Use the tab buttons to switch between models."
    )
    fig_growth = _build_p2_growth(data["proj2"])
    st.plotly_chart(fig_growth, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

While both machine learning models successfully capture the general upward growth trajectory of the forest over the seven-year horizon, they differ significantly in their ability to model the stand's true biological variability.

*   **Random Forest (RF) Excels at Variance:** The RF model tracks the mean field volume almost perfectly. More importantly, its predicted interquartile range (the green shaded area) perfectly mirrors the true structural spread of the forest (the purple shaded area), proving it can accurately model the natural heterogeneity of a growing stand.
*   **SVR Compresses the Population:** Conversely, the SVR model exhibits a slight but persistent underestimation of the mean volume as the trees mature. Furthermore, it artificially compresses the varianceâ€”shown by the noticeably narrower predicted interquartile rangeâ€”failing to fully capture the extremes of the population structure.

This visual confirms that the ensemble-based Random Forest is not just predicting the "average" tree accurately, but is successfully projecting the complex, diverse reality of the entire stand over an extended forecasting horizon.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- TPH scatter subplots --------------------------------------------
    _section("Stand Density Breakdown", "Volume Predictions by Trees per Hectare (TPH)")
    st.caption(
        "Each subplot shows one stand density treatment. "
        "Points are coloured by **stand age**; use the tab buttons to switch between models."
    )
    fig_tph = _build_p2_tph(data["proj2"])
    st.plotly_chart(fig_tph, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

Evaluating the models across different silvicultural conditions reveals a strong **inverse relationship between planting density and predictive accuracy** over the 7-year horizon.

As shown above, the Random Forest model performs exceptionally well in low-density stands (618 TPH; $R^2 = 0.91$), where trees have ample space to grow and individual crowns are easily delineated by LiDAR. However, as initial planting density increases to 1,853 TPH, accuracy drops significantly ($R^2 = 0.74$), accompanied by an increase in scatter and underprediction of larger trees. This drop-off underscores an operational challenge: in highly dense environments, intense early canopy interlocking obscures individual tree structures, introducing noise into the age-8 LiDAR metrics that subsequently degrades long-term yield forecasts.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- Temporal importance ---------------------------------------------
    _section("The Why", "How Feature Importance Shifts Over Time")
    st.caption(
        "Each line traces one predictor's importance (% increase in MSE) across age groups. "
        "Use the tab buttons to switch between model types. Only the top 10 features by "
        "average importance are shown."
    )
    fig_temp = _build_p2_temporal(data["proj2_age_importance"])
    st.plotly_chart(fig_temp, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

The temporal feature importance analysis reveals a fascinating biological narrative: **both machine learning models successfully captured the fundamental ecological shift of the maturing forest.**

While Random Forest and SVR utilize different specific features in their early predictions, they both exhibit a distinct, shared transition over the 7-year forecasting horizon:

*   **The "Free-to-Grow" Phase (Ages 9â€“11):** In the years immediately following the drone flight, yield predictions are dominated by Individual Tree Crown (ITC) metricsâ€”such as top height (`Z`), crown volume (`vol5`), and surface area (`sfa2`). At this stage, a tree's future yield is primarily dictated by its own established size and photosynthetic capacity.
*   **The Onset of Canopy Closure (Ages 12â€“15):** As the prediction window extends, the importance of individual size plateaus or declines, while the height-based Competition Index (`CI_Z`) surges dramatically. By age 13, `CI_Z` emerges as the undisputed dominant predictor in both models.

This proves that the algorithms are not just memorizing static patterns; they are dynamically mapping the transition from size-dependent growth to competition-dependent growth. It highlights exactly why spatially explicit competition metrics are absolutely vital for accurate, long-term yield forecasting.

</div>
""", unsafe_allow_html=True)


def _page_project3(data: dict) -> None:
    # ---- Narrative intro -------------------------------------------------
    st.markdown(_load_md("project3.md"), unsafe_allow_html=True)

    # ---- Key metrics row -------------------------------------------------
    _section("At a Glance", "Project 3 Summary Statistics")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Models Tested",  "7",             help="GRU Â· LSTM Â· RF Â· XGBoost Â· LightGBM Â· SVR Â· GBM")
    c2.metric("Spatial Unit",   "Plot Level",    help="Stand-level volume aggregation")
    c3.metric("RS Source",      "LiDAR + MS",    help="ALS point clouds + multispectral imagery")
    c4.metric("Key Covariate",  "Thinning",      help="Thinned vs. unthinned stands")

    st.markdown("---")

    # ---- Scatter with model tab buttons ----------------------------------
    _section("The Results", "Observed vs. Predicted Stand Volume")

    st.caption(
        "Use the tab buttons to switch between models. "
        "Points are coloured by **thinning status**. "
        "Hover for plot ID, TPH, and area metadata."
    )
    fig_scatter = proj3_plots.plot_p3_scatter(data["proj3"])
    st.plotly_chart(fig_scatter, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

When scaling from individual trees to plot-level predictions using continuous, open-source satellite data (Sentinel-1 & 2), the advanced Recurrent Neural Networks (**GRU and LSTM**) match and marginally outperform the industry-standard Random Forest model (all achieving an $R^2 \\approx 0.49$).

However, all seven models exhibit a persistent pattern of heteroscedasticity driven by **signal saturation**. While the algorithms perform reasonably well at predicting low to moderate volumes (points clustering near the 1:1 line), they systematically "flatline" and underpredict yield in high-volume plots (field volumes > 125 mÂ³/ha). This visualizes a fundamental limitation of optical and C-band SAR sensors: once a dense forest canopy closes, the satellite signal loses sensitivity to further biomass accumulation beneath the canopy, artificially capping the models' predictive range.

</div>
""", unsafe_allow_html=True)

    # ---- RMSE by TPH density category ------------------------------------
    _section("Density Sensitivity", "RMSE by Stand Density Category")
    st.caption(
        "Each panel shows one model's prediction error (RMSE) broken down by "
        "planting density group. Use the legend to identify density categories."
    )
    fig_rmse_tph = _build_p3_rmse_tph(data["proj3"])
    st.plotly_chart(fig_rmse_tph, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

Stratifying predictive error (RMSE) by initial planting density reveals a universal **"U-shaped" performance curve** across all seven algorithms. This highlights a critical operational sweet spot and a fundamental limitation of current satellite sensors:

*   **The Operational Sweet Spot (618â€“1236 TPH):** All models achieve their highest accuracy (lowest RMSE) in medium-density stands. This represents the optimal balance: the canopy is sufficiently closed to provide a strong, coherent remote sensing signal, but not so dense that it overwhelms the sensors.
*   **The Understory Noise Effect (<618 TPH):** In low-density stands, predictive error increases moderately. Because the sparse canopy does not fully cover the ground, the satellite sensors capture unwanted "noise" from the background soil and understory vegetation, confusing the biomass signal.
*   **The Saturation Barrier (>1237 TPH):** The most severe degradation in accuracy occurs in highly dense stands. This perfectly visualizes the well-documented phenomenon of **signal saturation**. Once a dense canopy fully closes, both optical reflectance and C-band SAR backscatter plateau, losing their sensitivity to further volume accumulation occurring beneath the canopy surface.

</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # ---- Feature importance ----------------------------------------------
    _section("The Why", "Remote Sensing Feature Importance by Model")
    st.caption(
        "Use the tab buttons to switch between model importance profiles. "
        "Longer bars indicate predictors with greater influence on stand volume estimates."
    )
    fig_imp = proj3_plots.plot_p3_importance(data["proj3_importance"])
    st.plotly_chart(fig_imp, use_container_width=True)

    st.markdown("""
<div style="font-size:1.15rem; line-height:1.75; color:#1A1A1A; margin: 18px 0 8px 0;">

**Key Takeaway:**

Deconstructing the models reveals a fundamental divergence in how ensemble algorithms versus neural networks interpret the fused satellite data. They arrive at similar predictive accuracies, but they rely on entirely different biophysical mechanisms:

*   **Random Forest (RF) Prioritizes Optical Reflectance:** The RF model relies overwhelmingly on Sentinel-2's Short-Wave Infrared band (`B11`). As a non-temporal model, RF favors spectral bands that provide strong, instantaneous correlations with canopy water content and canopy closureâ€”proxies for total biomass.
*   **Deep Learning (GRU & LSTM) Prioritizes SAR Structure:** Conversely, the recurrent neural networks identify Sentinel-1's C-band cross-polarized backscatter (`gamma_nought_VH`) as the single most critical driver of yield. Because GRU and LSTM architectures are explicitly designed to handle sequential data, their memory gates effectively filter out the high-frequency "noise" (like daily moisture changes) inherent in radar data, allowing them to isolate and track the gradual, underlying volumetric scattering of branches and needles as the trees grow.

This proves the tremendous value of **multi-sensor fusion**: providing both structural (SAR) and spectral (Optical) time-series data allows different machine learning architectures to play to their unique algorithmic strengths.

</div>
""", unsafe_allow_html=True)


# ---------------------------------------------------------------------------
# Sidebar
# ---------------------------------------------------------------------------
def _render_sidebar() -> str:
    with st.sidebar:
        st.markdown(f"""
        <div style="text-align:center; padding: 22px 0 14px 0;">
          <div style="font-size: 2.8rem; line-height:1;">ðŸŒ²</div>
          <p style="color:{_PALETTE['beige']}; font-size:0.7rem; text-transform:uppercase;
                    letter-spacing:2.5px; margin: 10px 0 4px 0;">PhD Dissertation</p>
          <p style="color:{_PALETTE['light']}; font-family:Georgia,serif; font-size:0.95rem;
                    line-height:1.45; margin:0;">
            <em>Pinus taeda</em><br>Yield Prediction
          </p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("---")

        page = st.radio(
            "Navigate to:",
            _PAGES,
            label_visibility="collapsed",
        )

        st.markdown("---")

        st.markdown(f"""
        <div style="font-size:0.72rem; line-height:1.8; color:{_PALETTE['beige']};">
          <strong style="color:{_PALETTE['light']};">Methodology</strong><br>
          Biometrics Â· Remote Sensing<br>
          Machine Learning Â· LiDAR<br><br>
          <strong style="color:{_PALETTE['light']};">Algorithms</strong><br>
          RF Â· XGBoost Â· LightGBM<br>
          GRU Â· LSTM Â· SVR Â· GBM<br><br>
          <strong style="color:{_PALETTE['light']};">Species</strong><br>
          <em>Pinus taeda</em> L.<br>
          Loblolly Pine
        </div>
        """, unsafe_allow_html=True)

    return page


# ---------------------------------------------------------------------------
# Entry point
# ---------------------------------------------------------------------------
def main() -> None:
    _inject_css()
    page = _render_sidebar()
    data = load_all_data()

    if page == "Home":
        _page_home()
    elif page == "Project 1: Individual Trees":
        _page_project1(data)
    elif page == "Project 2: Stand Dynamics":
        _page_project2(data)
    elif page == "Project 3: Remote Sensing":
        _page_project3(data)


if __name__ == "__main__":
    main()
